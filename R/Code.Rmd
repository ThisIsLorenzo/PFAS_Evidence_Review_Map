---
title: "Code"
author: "LR"
date: '2022-06-29'
output: html_document
---
# PFAS exposure of humans, animals and the environment: a systematic meta-review map and bibliometric analysis  

# supplementary Material - data processing and data visualization

# Setup and load packages

```{r setup, include=TRUE}
library(tidyverse)
library(here)
library(stringr)
library(knitr)
library(formatR)
library(forcats)
library(ggplot2)
library(hrbrthemes) 
library(patchwork)
library(bibliometrix)
library(igraph)


knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

```

# Load data

Manually extracted data using Google Forms is stored in the "data" folder. This data is splitted in four difference .csv files:
1. **Main.csv** = main data sheet for the systematic map
2. **AMSTAR2.csv** = AMSTAR2 quality assessment data sheet
3. **PFAS_types.csv** = data sheet about PFAS types investigated in the included systematic reviews
4. **Species.csv** = data sheet on species investigated in the included systematic reviews

Bibliographic data records are exported from Scopus (including cited references field) in .bib format and locally saved as **scopus.bib** in the "data" folder.

```{r load data}
mdata <- read_csv(here("data", "Main_data.csv"))
# Remove columns that are unnecessary for analysis (i.e., Timestamp, Initials_data_extraction, and initials_data_checked)
mdata <- mdata %>% 
  select(-c(Timestamp, Initials_data_extraction, initials_data_checked))

spdata <- read.csv(here("data", "Species_info.csv"))
# Remove columns that are unnecessary for analysis (i.e., Comment)
spdata <- spdata %>% 
  select(-Comment)
# Replace special characters that are exporting mistakes (e.g., replace "Ã¼" with "ü")
spdata <- apply(spdata, 2, function (x) gsub("â€™", "'", x))
spdata <- apply(spdata, 2, function (x) gsub("Ã¼", "ü", x))
spdata <- apply(spdata, 2, function (x) gsub("Ã©", "e", x))
spdata <- as_tibble(spdata)

qdata <- read.csv(here("data", "AMSTAR2_assessment.csv"))
# Remove columns that are unnecessary for analysis (i.e., Timestamp, Initials_data_extraction, initials_data_checked, and all answers comment [e.g., Q1_comment])
qdata <- qdata %>% 
  select(-c(Timestamp, Initials_data_extraction, initials_data_checked)) %>% 
  select(- ends_with("Comment"))
# Replace special characters that are exporting mistakes (e.g., replace "â€œYesâ€" with "Yes")
qdata <- apply(qdata, 2, function (x) gsub("â€œYesâ€", "Yes", x))
qdata <- apply(qdata, 2, function (x) gsub("â€Noâ€", "No", x))
qdata <- apply(qdata, 2, function (x) gsub("â€œCanâ€™t", "Cannot", x))
qdata <- apply(qdata, 2, function (x) gsub("â€", "", x))
qdata <- apply(qdata, 2, function (x) gsub("â€œ", "", x))
qdata <- as_tibble(qdata)

ptdata <- read.csv(here("data", "PFAS_types.csv"))
# change data format
ptdata <- ptdata %>% 
  select(Study_ID:PFAS_type) %>% 
  separate_rows(PFAS_type, sep = ', ')
```

# Merge relational datasheets

Here we merge data stored across different relational datasheets. This step is necessary to perform some of the analysis.

```{r merge data}

```

